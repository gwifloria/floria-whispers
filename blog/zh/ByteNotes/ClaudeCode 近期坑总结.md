
1. 如何更清晰地用语言描述清楚需求以及要求，提供大致解决思路，并列清期望结果，减少人和电脑的 context gap，是很重要的一个点，所以我认为写作确实也是很重要的一件事
2. AI 确实可以帮我实现需求，但如何更好地实现需求有时候也是需要结合人的判断的。比如我能看到一些 ![[Pasted image 20251130095602.png]]
![[Pasted image 20251202230924.png]]我分享两个印象比较深的坑，以及一些反思。

### 第一个坑：类型定义到处重复

我有个前后端一体的 Monorepo 项目，理论上接口类型应该共用一份。但让 Claude Code 帮我做一个完整的前后端功能时，它会在前端和后端各生成一份类型定义。

这导致什么问题呢？后面改需求的时候，我得改好几个地方，而且 AI 经常改漏。

后来我跟它约定了一个规范：**定义一个核心的 CoreType 放在公共包里，前后端各自去继承、补充自己需要的字段**。

但这里我犯了一个错——我没有及时把这个约定写进 `CLAUDE.md`，结果过几天又出现类似的问题，AI 又忘了。

### 第二个坑：本地能跑，部署就炸

这个坑更深一点。我在把 Express 和 Next.js 合并进 Turborepo 的时候，跟 AI 说我想把一些长时服务单独部署，比如邮件同步、接口轮询这种。

AI 看起来帮我做完了，本地测试也都能跑通。但一部署上去就出问题了——它把邮件同步的逻辑写在了 Next.js 的 API Routes 里。

问题在哪呢？我的前端是部署在 Vercel 的，那是 Serverless 环境，**函数执行有时间限制，不支持长连接**。这种长时任务根本跑不了。


这件事让我意识到：**AI 永远给你正反馈**。它不会主动说「这个方案有问题」，只会说「好的，帮你做完了」。等你踩坑了，它才说「哦，这里我没考虑到」。

---

### 第三个坑：解决出现的问题是AI的任务，怎么更好的解决是人的任务
![[Pasted image 20251203103104.png]]

---

### 我的反思

这两个坑表面上看是 AI 的问题，但反过来想，**核心其实是我没把上下文传递清楚**。

用好 AI 最关键的一点，就是要把自己的上下文尽可能无 Gap 地提供给它——需求背景、技术约束、部署环境这些，你脑子里觉得「这不是显而易见的吗」，但 AI 不知道。

而**「组织上下文」这件事本身就是一个能力**，我觉得很多人其实不太擅长，包括我自己。前面踩的坑，本质上就是我没把隐性知识显性化——没说清楚部署环境是 Serverless，没及时把约定写成文档。

这个能力不光是跟 AI 协作需要，跟人协作也一样。我自己在这方面还在刻意练习，比如现在会把思考过程、做过的决策、踩过的坑都记录下来。这样不管是给 AI 还是给未来的自己，上下文都更完整。
为了防止构建错误，会把高风险信息写死在代码
但是正确做法应该是在构建前检查是否有环境变量，如果缺失则应该报错
![[Pasted image 20251203110941.png]]